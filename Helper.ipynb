{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Helper.ipynb","provenance":[],"collapsed_sections":["E_sWBckXHTw8","2rzc15rJ6kuz","0ukn1mnjMJXV","JZW8ewYgAfs_","EhofuYwqHOLq"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"E_sWBckXHTw8"},"source":["# Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bOeD60-ZHS2u","executionInfo":{"status":"ok","timestamp":1636422445198,"user_tz":180,"elapsed":13784,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}},"outputId":"1ecede2e-08c5-46b3-c0e0-5d5d91ec821c"},"source":["import pandas as pd\n","!pip install pandas_summary\n","from pandas_summary import DataFrameSummary\n","import numpy as np\n","import datetime\n","!pip install isoweek\n","from isoweek import Week\n","from matplotlib import pyplot as plt\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","!pip install sklearn_pandas\n","from sklearn_pandas import DataFrameMapper\n","from sklearn.manifold import TSNE\n","from sklearn.decomposition import PCA\n","\n","from tensorflow import keras\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import Embedding, Input, Flatten, Concatenate, Dense, BatchNormalization, Activation, LeakyReLU, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.utils import to_categorical"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pandas_summary\n","  Downloading pandas_summary-0.0.7-py2.py3-none-any.whl (5.2 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandas_summary) (1.1.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pandas_summary) (1.19.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas_summary) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas_summary) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pandas_summary) (1.15.0)\n","Installing collected packages: pandas-summary\n","Successfully installed pandas-summary-0.0.7\n","Collecting isoweek\n","  Downloading isoweek-1.3.3-py2.py3-none-any.whl (7.1 kB)\n","Installing collected packages: isoweek\n","Successfully installed isoweek-1.3.3\n","Requirement already satisfied: sklearn_pandas in /usr/local/lib/python3.7/dist-packages (1.8.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from sklearn_pandas) (1.4.1)\n","Requirement already satisfied: pandas>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_pandas) (1.1.5)\n","Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from sklearn_pandas) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_pandas) (0.22.2.post1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.11.0->sklearn_pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.11.0->sklearn_pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.11.0->sklearn_pandas) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.15.0->sklearn_pandas) (1.0.1)\n"]}]},{"cell_type":"markdown","metadata":{"id":"2rzc15rJ6kuz"},"source":["# Funciones de preprocesamiento"]},{"cell_type":"code","metadata":{"id":"FKKcob_GAekA","executionInfo":{"status":"ok","timestamp":1636422445199,"user_tz":180,"elapsed":23,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def get_missing_columns(df):  # devuelve las columnas a las que les falten datos\n","    return list(df.columns[df.describe(include = 'all').loc['count']<len(df)])"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"QRs5WNvLC9W7","executionInfo":{"status":"ok","timestamp":1636422445199,"user_tz":180,"elapsed":22,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def join_df(left, right, left_on, right_on=None, join_test = False, test = pd.DataFrame()):\n","    if right_on is None: right_on = left_on\n","    train_merge = left.merge(right, how='left', left_on=left_on, right_on=right_on, \n","                      suffixes=(\"\", \"_y\"))\n","    if join_test == True: #si queremos unir la tabla de test con la misma tabla que unimos train\n","      test_merge = test.merge(right, how='left', left_on=left_on, right_on=right_on, \n","                      suffixes=(\"\", \"_y\"))\n","      return train_merge,test_merge\n","    else:\n","      return train_merge"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"og2YN_NpDCaF","executionInfo":{"status":"ok","timestamp":1636422445200,"user_tz":180,"elapsed":22,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def add_datepart(df):\n","    df.Date = pd.to_datetime(df.Date)\n","    df[\"Year\"] = df.Date.dt.year\n","    df[\"Month\"] = df.Date.dt.month\n","    df[\"Week\"] = df.Date.dt.week\n","    df[\"Day\"] = df.Date.dt.day\n","    "],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0ukn1mnjMJXV"},"source":["# Funciones de preprocesamiento de duraciones"]},{"cell_type":"code","metadata":{"id":"z9stjXMLMOnB","executionInfo":{"status":"ok","timestamp":1636422445201,"user_tz":180,"elapsed":23,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["class elapsed(object):\n","    def __init__(self, fld):\n","        self.fld = fld\n","        self.last = pd.to_datetime(np.nan)\n","        self.last_store = 0\n","        \n","    def get(self, row):\n","        if row.Store != self.last_store:\n","            self.last = pd.to_datetime(np.nan)\n","            self.last_store = row.Store\n","        if (row[self.fld]): self.last = row.Date\n","        return row.Date-self.last"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"x6Ye-TZjMPlU","executionInfo":{"status":"ok","timestamp":1636422445202,"user_tz":180,"elapsed":23,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def add_elapsed(df, fld, prefix):\n","    sh_el = elapsed(fld)\n","    df[prefix+fld] = df.apply(sh_el.get, axis=1)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JZW8ewYgAfs_"},"source":["# Funciones Baselines"]},{"cell_type":"code","metadata":{"id":"DZNaGF1JA-Xl","executionInfo":{"status":"ok","timestamp":1636422445202,"user_tz":180,"elapsed":22,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def get_metric(sales, sales_):\n","    return np.sqrt((((sales - sales_)/sales)**2).sum()/len(sales))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"nTmEWmZnA4FO","executionInfo":{"status":"ok","timestamp":1636422445203,"user_tz":180,"elapsed":23,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def rmspe(y_true, y_pred):\n","    return K.sqrt(K.mean(K.square((y_true - y_pred)/y_true)))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNfm-ikSA76U","executionInfo":{"status":"ok","timestamp":1636422445204,"user_tz":180,"elapsed":23,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def get_mean_by_column(column, sales_str):\n","    group_means_dict = {}\n","    group_mean_list = []\n","    for col_value, group_df in df_train.groupby(column):\n","        group_mean =  group_df[group_df[sales_str] > 0][sales_str].mean()\n","        group_means_dict[col_value] = group_mean\n","        group_mean_list.append(group_mean)\n","    print('Train:', get_metric(df_train[sales_str], \n","                               df_train[column].apply(group_means_dict.get)))\n","    print('Val:', get_metric(df_val[sales_str], \n","                             df_val[column].apply(group_means_dict.get)))\n","    return group_means_dict, group_mean_list"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuCW6jtLAh4L","executionInfo":{"status":"ok","timestamp":1636422445204,"user_tz":180,"elapsed":23,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def get_keras_LR(X_columns, hidden_units=1):\n","    inputs = []\n","    activation = 'linear'\n","    if hidden_units>1:\n","        activation = 'relu'\n","    for i, col in enumerate(X_columns):\n","        inp = Input(shape=(X_train[i].shape[1],), name=f\"{col}_input\")\n","        inputs.append(inp)\n","    if len(X_columns)>1:\n","        concat_out = Concatenate()(inputs)\n","        dense_out = Dense(hidden_units, name='Dense', activation=activation)(concat_out)\n","    else:\n","        dense_out = Dense(hidden_units, name='Dense', activation=activation)(inputs[0])\n","    if hidden_units>1:\n","        dense_out = Dense(1, name='Dense_out')(dense_out)\n","    model = Model(inputs, dense_out)\n","    model.compile(optimizers.Adam(lr=0.0001), loss='mse', metrics=[rmspe, 'mse'])\n","    return model\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"RnAgM05mAoj6","executionInfo":{"status":"ok","timestamp":1636422445205,"user_tz":180,"elapsed":24,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def get_embedings_NN(X_columns, hidden_units = 20, activation = 'relu'):\n","    embed_outs = []\n","    inputs = []\n","    for i, col in enumerate(X_columns):\n","        inp = Input(shape=(1,), name=f\"{col}_input\")\n","        inputs.append(inp)\n","        if col in embed_outs_dict:\n","            embed_out = Embedding(len(np.unique(X_train[i])), embed_outs_dict[col], name=f\"{col}_embedding\", mask_zero=False)(inp)\n","            out = Flatten(name=f\"{col}_flatten\")(embed_out)\n","            embed_outs.append(out)\n","        else:\n","            embed_outs.append(inp)\n","        \n","    if len(X_columns)>1:\n","        concat_out = Concatenate()(embed_outs)\n","        dense_out = Dense(hidden_units, activation=activation)(concat_out)\n","    else:\n","        dense_out = Dense(hidden_units, activation=activation)(out)\n","    out = Dense(1)(dense_out)\n","    model = Model(inputs, out)\n","    model.compile(optimizers.Adam(lr=0.0001), loss='mse', metrics=[rmspe, 'mse'])\n","    return model"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"02ErpMsoAvIT","executionInfo":{"status":"ok","timestamp":1636422445205,"user_tz":180,"elapsed":23,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def plot_embed(layer_name, cat_names):\n","    Y = model.get_layer(layer_name).get_weights()[0]\n","    print(Y.shape)\n","    plt.figure(figsize=(8,8))\n","    plt.scatter(-Y[:, 0], -Y[:, 1])\n","    for i, txt in enumerate(cat_names):\n","        plt.annotate(txt, (-Y[i, 0],-Y[i, 1]), xytext = (-5, 8), textcoords = 'offset points')"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0aD0r0BmHNXJ"},"source":["# Función Embedding"]},{"cell_type":"code","metadata":{"id":"fzv-LzYpA0SY","executionInfo":{"status":"ok","timestamp":1636422445205,"user_tz":180,"elapsed":22,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["# Función que crea las capas de Embedding para las variables categoricas:\n","def get_cat_vars_model(cat_vars, uniques, cat_var_dict):\n","    cat_vars_embed_outs = [] # Lista de las capas de embeddings para cada variable categorica.\n","    cat_var_inputs = [] # Lista de los inputs a las capas de embeddings de cada variable categorica.\n","    for cat_var in cat_vars:\n","        # Se define la entrada unica (una sola variable) de una capa embedding.\n","        cat_var_in = Input(shape=(1,), name=f\"{cat_var}_input\")\n","        # Se agrega ese input a la lista:\n","        cat_var_inputs.append(cat_var_in)\n","        # Se crea la capa de embedding de salida:\n","        embed_out = Embedding(uniques[cat_var][0], cat_var_dict[cat_var], name=f'{cat_var}_Embed')(cat_var_in)\n","        # Hay que hacerle un reshape a esta capa de salida:\n","        flatten_out = Flatten(name=f\"{cat_var}_flat\")(embed_out)\n","        # Se agrega esta capa con su reshape a la lista de embeddings que devuelve:\n","        cat_vars_embed_outs.append(flatten_out)\n","    return cat_var_inputs, cat_vars_embed_outs"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0oQ0m3qeEgK","executionInfo":{"status":"ok","timestamp":1636422445206,"user_tz":180,"elapsed":23,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["# Función que crea las capas de Embedding para las variables categoricas:\n","def get_cat_vars_model2(cat_vars, uniques, cat_var_dict):\n","    cat_vars_embed_outs = [] # Lista de las capas de embeddings para cada variable categorica.\n","    cat_var_inputs = [] # Lista de los inputs a las capas de embeddings de cada variable categorica.\n","    for cat_var in cat_vars:\n","        # Se define la entrada unica (una sola variable) de una capa embedding.\n","        cat_var_in = Input(shape=(1,), name=f\"{cat_var}_input\")\n","        # Se agrega ese input a la lista:\n","        cat_var_inputs.append(cat_var_in)\n","        # Se crea la capa de embedding de salida:\n","        embed_out = Embedding(uniques[cat_var][0]+1, cat_var_dict[cat_var], name=f'{cat_var}_Embed')(cat_var_in)\n","        # Hay que hacerle un reshape a esta capa de salida:\n","        flatten_out = Flatten(name=f\"{cat_var}_flat\")(embed_out)\n","        # Se agrega esta capa con su reshape a la lista de embeddings que devuelve:\n","        cat_vars_embed_outs.append(flatten_out)\n","    return cat_var_inputs, cat_vars_embed_outs"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EhofuYwqHOLq"},"source":["# Función creación capas de entrada variables continuas"]},{"cell_type":"code","metadata":{"id":"bDgKP9PPHSoc","executionInfo":{"status":"ok","timestamp":1636422445206,"user_tz":180,"elapsed":23,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def get_cont_vars_input(contin_vars, dense_layer=False):\n","    cont_vars_inputs = [] # Lista de los inputs de cada capa densa para cada variable continua.\n","    cont_vars_outputs = [] # Lista de las capas densas para cada variable continua.\n","    for cont_var in contin_vars:\n","        # Se define la entrada unica (una sola variable) de una capa.\n","        cont_var_in = Input(shape=(1,), name=f\"{cont_var}_input\")\n","        # Se agrega ese input a la lista:\n","        cont_vars_inputs.append(cont_var_in)\n","        if dense_layer: \n","            cont_var_out = Dense(1, name=f\"{cont_var}_input\", activation = 'linear')(cont_var_in)\n","            cont_vars_outputs.append(cont_var_out)\n","        else:\n","            cont_vars_outputs.append(cont_var_in)\n","    return cont_vars_inputs, cont_vars_outputs"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lbBJeLafQ7Aq"},"source":["# Creación de modelo"]},{"cell_type":"code","metadata":{"id":"S3HbCLvJRD2V","executionInfo":{"status":"ok","timestamp":1636422445206,"user_tz":180,"elapsed":23,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def MLP_layers(embeddings, contin_inputs, l2_lambda, kernel_in, cant_capas, cant_neuronas = [1], activation_func = [\"linear\"], alpha = 0.3):\n","  max_capas = 0\n","  # Se combinan todos los inputs en una sola capa de inputs:\n","  merged = Concatenate(name='All_Concatenate')(embeddings + contin_inputs)\n","\n","  # Se inicializa la primera capa:\n","  x = Dense(cant_neuronas[max_capas], kernel_initializer= kernel_in, kernel_regularizer=l2(l2_lambda))(merged)\n","  if activation_func[max_capas] == \"LeakyReLU\":\n","    x = LeakyReLU(alpha=alpha[max_capas])(x)\n","  else:\n","    x = Activation(activation_func[max_capas])(x)\n","  \n","  # Se suma uno a max_capas:\n","  max_capas = 1\n","\n","  # se arman las siguientes capas:\n","  while cant_capas > max_capas:\n","    x = Dense(cant_neuronas[max_capas], kernel_initializer= kernel_in, kernel_regularizer=l2(l2_lambda))(x)\n","    if activation_func[max_capas] == \"LeakyReLU\":\n","      x = LeakyReLU(alpha=alpha[max_capas])(x)\n","    else:\n","      x = Activation(activation_func[max_capas])(x)\n","    max_capas += 1\n","  \n","  return x"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xfe9JJBGHhso","executionInfo":{"status":"ok","timestamp":1636422445207,"user_tz":180,"elapsed":23,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def crear_MLP(add_customers, cat_var_inputs, cont_vars_inputs, layers, output_activation):\n","  # Creamos el output de Sales:\n","  output_1 = Dense(1, name='Sales', activation=output_activation)(layers)\n","  # El modelo se crea en base a si también queremos predecir customers:\n","  if add_customers:\n","    output_2 = Dense(1, name='Customers', activation=output_activation)(layers)\n","    model = Model(cat_var_inputs + cont_vars_inputs, [output_1, output_2])\n","  else: \n","    model = Model(cat_var_inputs + cont_vars_inputs, [output_1])\n","  return model"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O7CZtDMhJGNZ"},"source":["# Funciones de metricas"]},{"cell_type":"code","metadata":{"id":"JLm7CWltHWs7","executionInfo":{"status":"ok","timestamp":1636422445207,"user_tz":180,"elapsed":23,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def rmspe(y_true, y_pred):\n","    return K.sqrt(K.mean(K.square((y_true - y_pred)/y_true)))"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"_gFGPPlqHYN1","executionInfo":{"status":"ok","timestamp":1636422445207,"user_tz":180,"elapsed":22,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def get_metric(df, sales_):\n","    return np.sqrt((((df['Sales'] - sales_)/df['Sales'])**2).mean())"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eiSjOkzLgM-q"},"source":["# Entrenamiento y obtención del modelo"]},{"cell_type":"code","metadata":{"id":"VZ_GNKST3Afn","executionInfo":{"status":"ok","timestamp":1636422445543,"user_tz":180,"elapsed":358,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def obtener_x_y(df_train,df_val,df_test,all_vars,add_customers=True,log_output=False):\n","\n","  X_train = np.hsplit(df_train[all_vars].values, len(all_vars))\n","  X_val = np.hsplit(df_val[all_vars].values, len(all_vars))\n","  X_test = np.hsplit(df_test[all_vars].values, len(all_vars))\n","\n","  if add_customers:\n","      y_out_columns = ['Sales', 'Customers']\n","  else:\n","      y_out_columns = ['Sales']\n","\n","  y_norm =[]\n","      \n","  if log_output:\n","      # Escala logaritmica\n","      df = pd.concat([df_train, df_val], axis=0)\n","      max_log_y = np.max(np.log(df[y_out_columns])).values\n","      y_train = np.log(df_train[y_out_columns].values)/max_log_y\n","      y_val = np.log(df_val[y_out_columns].values)/max_log_y\n","\n","      y_norm.append(max_log_y)\n","  else: \n","      # Normalizacion\n","      y_mean = df_train[y_out_columns].mean().values\n","      y_std = df_train[y_out_columns].std().values\n","\n","      y_max = df_train[y_out_columns].max().values\n","      y_train = df_train[y_out_columns].values/y_max\n","      y_val = df_val[y_out_columns].values/y_max\n","\n","      y_norm.append(y_mean)\n","      y_norm.append(y_std)\n","      y_norm.append(y_max)\n","\n","  y_train = np.hsplit(y_train, y_train.shape[1])\n","  y_val = np.hsplit(y_val, y_val.shape[1])\n","\n","  return X_train,X_val,X_test,y_train,y_val,y_norm"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"nekZMjWb5XxP","executionInfo":{"status":"ok","timestamp":1636422445543,"user_tz":180,"elapsed":7,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def entrenar_MLP(X_train,X_val,y_train,y_val,all_vars,model,add_customers=True,log_output=False,lr=0.001,metrics=['mse', rmspe],loss='mse',model_chosen='bestmodel.hdf5',epochs = 20,batch_size = 256,verbose=2):\n","\n","  model.compile(optimizer=Adam(learning_rate=lr), metrics=metrics, loss=loss)\n","  \n","  if add_customers:\n","      checkpoint = ModelCheckpoint(model_chosen, monitor='val_Sales_mse', verbose=verbose, save_best_only=True)\n","  else:\n","      checkpoint = ModelCheckpoint(model_chosen, monitor='val_loss', verbose=verbose, save_best_only=True)\n","\n","  history = model.fit(X_train, y_train, validation_data=(X_val, y_val),  epochs=epochs, batch_size=batch_size, callbacks=[checkpoint], verbose=verbose)\n","\n","  return history,model"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"355XS0YFPcHl","executionInfo":{"status":"ok","timestamp":1636422445543,"user_tz":180,"elapsed":6,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def entrenar_MLP2(X_train,X_val,y_train,y_val,all_vars,model,add_customers=True,log_output=False,lr=0.001,metrics=['mse', rmspe],loss='mse',model_chosen='bestmodel.hdf5',epochs = 20,batch_size = 256,verbose=2):\n","\n","  print(1)\n","  model.compile(optimizer=Adam(learning_rate=lr), metrics=metrics, loss=loss)\n","  print(2)\n","  if add_customers:\n","      print(3)\n","      checkpoint = ModelCheckpoint(model_chosen, monitor='val_Sales_mse', verbose=verbose, save_best_only=True)\n","  else:\n","      checkpoint = ModelCheckpoint(model_chosen, monitor='val_loss', verbose=verbose, save_best_only=True)\n","\n","  print(4)\n","  history = model.fit(X_train, y_train, validation_data=(X_val, y_val),  epochs=epochs, batch_size=batch_size, callbacks=[checkpoint], verbose=verbose)\n","  print(5)\n","  return history,model"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OECYgopPSY6l"},"source":["# Obtención de métricas"]},{"cell_type":"code","metadata":{"id":"QybyIVMpSa6u","executionInfo":{"status":"ok","timestamp":1636422445544,"user_tz":180,"elapsed":7,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def metricas_MLP(X_val, y_val,model,lr=0.001,metrics=['mse', rmspe],loss='mse',model_chosen='bestmodel.hdf5'):\n","\n","  model.compile(optimizer=Adam(learning_rate=lr), metrics=metrics, loss=loss)\n","  model.load_weights(model_chosen)\n","  res_metrics = model.evaluate(X_val, y_val,return_dict = True)\n","\n","  return res_metrics"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"hEV7LYy9dtei","executionInfo":{"status":"ok","timestamp":1636422445544,"user_tz":180,"elapsed":6,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def crossval_score_MLP(df,df_test,all_vars,model,k=5,add_customers=True,log_output=False,lr=0.001,metrics=['mse', rmspe],loss='mse',epochs = 20,batch_size = 256,verbose=2):\n","\n","  metrics_cross = []\n","\n","  for i in range(8-k,8):\n","    df_cross_train = df[df.Date < datetime.datetime(2015, i, 1)]  \n","    df_cross_val = df[df.Date >= datetime.datetime(2015, i, 1)]\n","    df_cross_val = df_cross_val[df.Date < datetime.datetime(2015, i+1, 1)]\n","\n","    print(f'Fechas en df_train:, {min(df_cross_train.Date)}, - {max(df_cross_train.Date)}')\n","    print(f'Fechas en df_val:, {min(df_cross_val.Date)}, - {max(df_cross_val.Date)}')\n","\n","    X_cross_train,X_cross_val,X_cross_test,y_cross_train,y_cross_val,y_norm = obtener_x_y(df_cross_train,df_cross_val,df_test,all_vars,add_customers=add_customers,log_output=log_output)  \n","\n","    model_chosen=f'modelos generados/bestmodel_add_customers_{add_customers}_log_output_{log_output}_lr_{lr}_batch_size_{batch_size}_crossval_{i}.hdf5'\n","\n","    history,model_cross = entrenar_MLP(X_cross_train,X_cross_val,y_cross_train,y_cross_val,all_vars,model=model,add_customers=add_customers,log_output=log_output,lr=lr,metrics=metrics,loss=loss,model_chosen=model_chosen,epochs = epochs,batch_size = batch_size,verbose=verbose)  \n","\n","    metric_cross = metricas_MLP(X_cross_val,y_cross_val,model_cross,model_chosen=model_chosen)    \n","    metrics_cross.append(metric_cross['Sales_rmspe'])\n","\n","  return metrics_cross"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"07W_ioArUuiQ","executionInfo":{"status":"ok","timestamp":1636422445544,"user_tz":180,"elapsed":6,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def crossval_score_MLP_nuestro(df,df_test,all_vars,model,k=5,add_customers=True,log_output=False,lr=0.001,metrics=['mse', rmspe],loss='mse',epochs = 20,batch_size = 256,verbose=2):\n","\n","  metrics_cross = []\n","\n","  for i in range(8-k,8):\n","    df_cross_train = df[df.Date < datetime.datetime(2015, i, 1)]  \n","    df_cross_val = df[df.Date >= datetime.datetime(2015, i, 1)]\n","    df_cross_val = df_cross_val[df.Date < datetime.datetime(2015, i+1, 1)]\n","\n","    print(f'Fechas en df_train:, {min(df_cross_train.Date)}, - {max(df_cross_train.Date)}')\n","    print(f'Fechas en df_val:, {min(df_cross_val.Date)}, - {max(df_cross_val.Date)}')\n","\n","    X_cross_train,X_cross_val,X_cross_test,y_cross_train,y_cross_val,y_norm = obtener_x_y(df_cross_train,df_cross_val,df_test,all_vars,add_customers=add_customers,log_output=log_output)  \n","\n","    model_chosen=f'modelos generados/bestmodel_nuestro_add_customers_{add_customers}_log_output_{log_output}_lr_{lr}_batch_size_{batch_size}_crossval_{i}.hdf5'\n","\n","    history,model_cross = entrenar_MLP(X_cross_train,X_cross_val,y_cross_train,y_cross_val,all_vars,model=model,add_customers=add_customers,log_output=log_output,lr=lr,metrics=metrics,loss=loss,model_chosen=model_chosen,epochs = epochs,batch_size = batch_size,verbose=verbose)  \n","\n","    metric_cross = metricas_MLP(X_cross_val,y_cross_val,model_cross,model_chosen=model_chosen)    \n","    metrics_cross.append(metric_cross['Sales_rmspe'])\n","\n","  return metrics_cross"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"WpqalgytXniM","executionInfo":{"status":"ok","timestamp":1636422445545,"user_tz":180,"elapsed":7,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def prom_metrics(df,df_test,all_vars,model,k=5,add_customers=True,log_output=False,lr=0.001,metrics=['mse', rmspe],loss='mse',epochs = 20,batch_size = 256):\n","  metrics_cross = []\n","  loss_cross = []\n","  for i in range(8-k,8):\n","    # Se dividen los df:\n","    df_cross_train = df[df.Date < datetime.datetime(2015, i, 1)]\n","    df_cross_val = df[df.Date >= datetime.datetime(2015, i, 1)]\n","    df_cross_val = df_cross_val[df.Date < datetime.datetime(2015, i+1, 1)]\n","  \n","    # Se normalizan y crean los X_val e y_val:\n","    X_train,X_val,X_test,y_train,y_val,y_norm = obtener_x_y(df_cross_train,df_cross_val,df_test,all_vars,add_customers=add_customers,log_output=log_output)\n","    models_chosen=f'modelos generados/bestmodel_add_customers_{add_customers}_log_output_{log_output}_lr_{lr}_batch_size_{batch_size}_crossval_{i}.hdf5'\n","\n","    # se calcula la metrica rmspe y loss para cada modelo:\n","    metric_cross = metricas_MLP(X_val,y_val,model,model_chosen=models_chosen)\n","    metrics_cross.append(metric_cross['Sales_rmspe'])\n","    loss_cross.append(metric_cross['Sales_loss'])\n","\n","    # Se saca el mean de cada variable:\n","    mean_metrics_cross = np.mean(metrics_cross)\n","    mean_loss_cross = np.mean(loss_cross)\n","\n","  return metrics_cross, loss_cross, mean_metrics_cross, mean_loss_cross"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"M87Mw5zIX_Fs","executionInfo":{"status":"ok","timestamp":1636422445545,"user_tz":180,"elapsed":6,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def prom_metrics_nuestro(df,df_test,all_vars,model,k=5,add_customers=True,log_output=False,lr=0.001,metrics=['mse', rmspe],loss='mse',epochs = 20,batch_size = 256):\n","  metrics_cross = []\n","  loss_cross = []\n","  for i in range(8-k,8):\n","    # Se dividen los df:\n","    df_cross_train = df[df.Date < datetime.datetime(2015, i, 1)]\n","    df_cross_val = df[df.Date >= datetime.datetime(2015, i, 1)]\n","    df_cross_val = df_cross_val[df.Date < datetime.datetime(2015, i+1, 1)]\n","  \n","    # Se normalizan y crean los X_val e y_val:\n","    X_train,X_val,X_test,y_train,y_val,y_norm = obtener_x_y(df_cross_train,df_cross_val,df_test,all_vars,add_customers=add_customers,log_output=log_output)\n","    models_chosen=f'modelos generados/bestmodel_nuestro_add_customers_{add_customers}_log_output_{log_output}_lr_{lr}_batch_size_{batch_size}_crossval_{i}.hdf5'\n","\n","    # se calcula la metrica rmspe y loss para cada modelo:\n","    metric_cross = metricas_MLP(X_val,y_val,model,model_chosen=models_chosen)\n","    metrics_cross.append(metric_cross['Sales_rmspe'])\n","    loss_cross.append(metric_cross['Sales_loss'])\n","\n","    # Se saca el mean de cada variable:\n","    mean_metrics_cross = np.mean(metrics_cross)\n","    mean_loss_cross = np.mean(loss_cross)\n","\n","  return metrics_cross, loss_cross, mean_metrics_cross, mean_loss_cross"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DNfKLMElzuLI"},"source":["# Obtención de predicciones"]},{"cell_type":"code","metadata":{"id":"hZnwid88z2o_","executionInfo":{"status":"ok","timestamp":1636422445545,"user_tz":180,"elapsed":6,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def predic_MLP(df_test,X_test,y_norm,model,add_customers=True,log_output=False,lr=0.001,metrics=['mse', rmspe],loss='mse',model_chosen='bestmodel.hdf5',verbose=2):\n","\n","  model.compile(optimizer=Adam(learning_rate=lr), metrics=metrics, loss=loss)\n","  model.load_weights(model_chosen)\n","\n","  if log_output:\n","    max_log_y = y_norm[0]\n","    if add_customers:\n","        y_pred_test = np.exp(model.predict(X_test, verbose=1)[0][:, 0]*max_log_y[0])\n","    else:\n","        y_pred_test = np.exp(model.predict(X_test, verbose=1)*max_log_y)[:,0]\n","  else:\n","    y_mean = y_norm[0]\n","    y_std = y_norm[1]\n","    y_max = y_norm[2]\n","    if add_customers:\n","        y_pred_test = (model.predict(X_test, verbose=1)[0]*y_std[0] + y_mean[0])[:,0]\n","    else:\n","\n","        y_pred_test = model.predict(X_test, verbose=1)[:,0]*y_max\n","\n","  y_pred_test[df_test['Open'] == 0] = 0\n","\n","  return y_pred_test"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CsCryKdpJJ7e"},"source":["# Funciones de ploteo"]},{"cell_type":"code","metadata":{"id":"K7a_FwvXHaeG","executionInfo":{"status":"ok","timestamp":1636422445546,"user_tz":180,"elapsed":7,"user":{"displayName":"Melina Leonor Piacentino Castaño","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01904401178350893377"}}},"source":["def plot_embed(model,layer_name, cat_names):\n","    Y = model.get_layer(layer_name).get_weights()[0]\n","    print(Y.shape)\n","    plt.figure(figsize=(8,8))\n","    plt.scatter(-Y[:, 0], -Y[:, 1])\n","    for i, txt in enumerate(cat_names):\n","        plt.annotate(txt, (-Y[i, 0],-Y[i, 1]), xytext = (-5, 8), textcoords = 'offset points')"],"execution_count":30,"outputs":[]}]}